{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d86459781eb9ef",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM, Reshape, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from img2vec import rgb2emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af882f020c34df5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38721be792e5b56b",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Print GPU information\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
    "\n",
    "    # Set memory growth to avoid using all GPU memory\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    print(\"GPU is available for TensorFlow!\")\n",
    "else:\n",
    "    print(\"No GPU found. TensorFlow will use CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893bb327e76005c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235445b29b5279c",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de63a3a7caf677",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3845e0de39192",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..', '..', 'data')\n",
    "train_data = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "val_data = pd.read_csv(os.path.join(data_dir, 'val.csv'))\n",
    "test_data = pd.read_csv(os.path.join(data_dir, 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dbb3e686f34058",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Print dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55933a2859e07c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ca055ad65ba02",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Check if images exist and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0dedfd8591c19",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_img_path(row):\n",
    "    return os.path.join(data_dir, 'faces', row['user_id'], \n",
    "                      f\"coarse_tilt_aligned_face.{row['face_id']}.{row['original_image']}\")\n",
    "\n",
    "train_data['img_path'] = train_data.apply(construct_img_path, axis=1)\n",
    "val_data['img_path'] = val_data.apply(construct_img_path, axis=1)\n",
    "test_data['img_path'] = test_data.apply(construct_img_path, axis=1)\n",
    "\n",
    "train_data['img_exists'] = train_data['img_path'].apply(os.path.exists)\n",
    "val_data['img_exists'] = val_data['img_path'].apply(os.path.exists)\n",
    "test_data['img_exists'] = test_data['img_path'].apply(os.path.exists)\n",
    "\n",
    "# Filter to include only rows where images exist\n",
    "train_data = train_data[train_data['img_exists'] == True]\n",
    "val_data = val_data[val_data['img_exists'] == True]\n",
    "test_data = test_data[test_data['img_exists'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81036f8022ff3853",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86e11e65c9b59b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('age_encoder.pkl') and os.path.exists('gender_encoder.pkl'):\n",
    "    age_encoder = joblib.load('age_encoder.pkl')\n",
    "    gender_encoder = joblib.load('gender_encoder.pkl')\n",
    "    print(\"Age and gender encoders loaded successfully.\")\n",
    "    \n",
    "    # Add these lines to encode train data when loading existing encoders\n",
    "    train_data['age_encoded'] = age_encoder.transform(train_data['age'])\n",
    "    train_data['gender_encoded'] = gender_encoder.transform(train_data['gender'])\n",
    "else:\n",
    "    # Remove rare classes\n",
    "    age_counts = train_data['age'].value_counts()\n",
    "    gender_counts = train_data['gender'].value_counts()\n",
    "    rare_ages = age_counts[age_counts < 5].index.tolist()\n",
    "    rare_genders = gender_counts[gender_counts < 5].index.tolist()\n",
    "    \n",
    "    # Filter data\n",
    "    train_data = train_data[~train_data['age'].isin(rare_ages) & ~train_data['gender'].isin(rare_genders)]\n",
    "    \n",
    "    # Create encoders\n",
    "    age_encoder = LabelEncoder()\n",
    "    gender_encoder = LabelEncoder()\n",
    "    train_data['age_encoded'] = age_encoder.fit_transform(train_data['age'])\n",
    "    train_data['gender_encoded'] = gender_encoder.fit_transform(train_data['gender'])\n",
    "    \n",
    "    # Save encoders\n",
    "    joblib.dump(age_encoder, 'age_encoder.pkl')\n",
    "    joblib.dump(gender_encoder, 'gender_encoder.pkl')\n",
    "    print(\"Encoders created and saved.\")\n",
    "\n",
    "# Filter validation and test data to include only seen classes\n",
    "val_data = val_data[val_data['age'].isin(age_encoder.classes_)]\n",
    "val_data = val_data[val_data['gender'].isin(gender_encoder.classes_)]\n",
    "test_data = test_data[test_data['age'].isin(age_encoder.classes_)]\n",
    "test_data = test_data[test_data['gender'].isin(gender_encoder.classes_)]\n",
    "\n",
    "# Encode the labels\n",
    "val_data['age_encoded'] = age_encoder.transform(val_data['age'])\n",
    "val_data['gender_encoded'] = gender_encoder.transform(val_data['gender'])\n",
    "test_data['age_encoded'] = age_encoder.transform(test_data['age'])\n",
    "test_data['gender_encoded'] = gender_encoder.transform(test_data['gender'])\n",
    "\n",
    "num_age_classes = len(age_encoder.classes_)\n",
    "num_gender_classes = len(gender_encoder.classes_)\n",
    "print(f\"Age classes: {age_encoder.classes_}\")\n",
    "print(f\"Gender classes: {gender_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a32b633a781e0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Define function that processes features in batches and stores them to avoid recomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f7f32c0f8db63b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_and_save_features(image_paths, output_file, batch_size=64):\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading pre-processed features from {output_file}\")\n",
    "        return np.load(output_file)\n",
    "\n",
    "    print(f\"Processing {len(image_paths)} images and saving to {output_file}\")\n",
    "    all_features = []\n",
    "\n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i + batch_size]\n",
    "        print(f\"Processing batch {i // batch_size + 1}/{math.ceil(len(image_paths) / batch_size)}\")\n",
    "        batch_features = rgb2emb(batch_paths)\n",
    "        all_features.append(batch_features)\n",
    "\n",
    "    all_features = np.vstack(all_features)\n",
    "    np.save(output_file, all_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c84b3e3ec33a80",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Process and save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4586caadd1345a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('train_features.npy'):\n",
    "    train_features = preprocess_and_save_features(train_data['img_path'].tolist(), 'train_features.npy')\n",
    "    val_features = preprocess_and_save_features(val_data['img_path'].tolist(), 'val_features.npy')\n",
    "    test_features = preprocess_and_save_features(test_data['img_path'].tolist(), 'test_features.npy')\n",
    "else:\n",
    "    train_features = np.load('train_features.npy')\n",
    "    val_features = np.load('val_features.npy')\n",
    "    test_features = np.load('test_features.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4929715b5d7e0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5836ec7182bdfd0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('feature_scaler.pkl'):\n",
    "    scaler = joblib.load('feature_scaler.pkl')\n",
    "    print(\"Feature scaler loaded successfully.\")\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_features)\n",
    "    joblib.dump(scaler, 'feature_scaler.pkl')\n",
    "    print(\"Feature scaler created and saved.\")\n",
    "\n",
    "train_features_scaled = scaler.transform(train_features)\n",
    "val_features_scaled = scaler.transform(val_features)\n",
    "test_features_scaled = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55515eb23e19e756",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Define LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa01d2b749bc006",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reshape_features_for_lstm(features, time_steps=16):\n",
    "    \"\"\"Reshape features to be compatible with LSTM input shape (batch, time_steps, features)\"\"\"\n",
    "    feature_dim = features.shape[1]\n",
    "    # Determine the feature size per time step\n",
    "    features_per_step = feature_dim // time_steps\n",
    "    \n",
    "    # If features aren't cleanly divisible, we'll pad\n",
    "    if feature_dim % time_steps != 0:\n",
    "        pad_size = time_steps - (feature_dim % time_steps)\n",
    "        features = np.pad(features, ((0, 0), (0, pad_size)), 'constant')\n",
    "        feature_dim = features.shape[1]\n",
    "        features_per_step = feature_dim // time_steps\n",
    "    \n",
    "    # Reshape to (batch, time_steps, features_per_step)\n",
    "    return features.reshape(features.shape[0], time_steps, features_per_step)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "time_steps = 16  # You can adjust this value\n",
    "train_features_lstm = reshape_features_for_lstm(train_features_scaled, time_steps)\n",
    "val_features_lstm = reshape_features_for_lstm(val_features_scaled, time_steps)\n",
    "test_features_lstm = reshape_features_for_lstm(test_features_scaled, time_steps)\n",
    "\n",
    "def create_lstm_age_model(input_shape, num_age_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(input_layer)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Bidirectional(LSTM(64))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    age_output = Dense(num_age_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=age_output)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_lstm_gender_model(input_shape, num_gender_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(input_layer)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Bidirectional(LSTM(64))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    gender_output = Dense(num_gender_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=gender_output)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create LSTM models\n",
    "lstm_input_shape = (train_features_lstm.shape[1], train_features_lstm.shape[2])\n",
    "age_model = create_lstm_age_model(lstm_input_shape, num_age_classes)\n",
    "gender_model = create_lstm_gender_model(lstm_input_shape, num_gender_classes)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"Age Model Summary:\")\n",
    "age_model.summary()\n",
    "print(\"\\nGender Model Summary:\")\n",
    "gender_model.summary()\n",
    "\n",
    "# Define callbacks for age model\n",
    "age_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_lstm_age_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Define callbacks for gender model\n",
    "gender_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_lstm_gender_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19e985a668e8d9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Compute class weights and get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a6d687592498a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_age_labels = train_data['age_encoded'].values\n",
    "train_gender_labels = train_data['gender_encoded'].values\n",
    "val_age_labels = val_data['age_encoded'].values\n",
    "val_gender_labels = val_data['gender_encoded'].values\n",
    "\n",
    "age_weights = compute_class_weight('balanced', classes=np.unique(train_data['age_encoded']), \n",
    "                                  y=train_data['age_encoded'])\n",
    "gender_weights = compute_class_weight('balanced', classes=np.unique(train_data['gender_encoded']), \n",
    "                                     y=train_data['gender_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4641fbd372f581",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d94e824f88d4fb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Training the LSTM age model...\")\n",
    "age_history = age_model.fit(\n",
    "    train_features_lstm,\n",
    "    train_age_labels,\n",
    "    validation_data=(val_features_lstm, val_age_labels),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=age_callbacks,\n",
    "    class_weight=dict(enumerate(age_weights))\n",
    ")\n",
    "\n",
    "print(\"Training the LSTM gender model...\")\n",
    "gender_history = gender_model.fit(\n",
    "    train_features_lstm,\n",
    "    train_gender_labels,\n",
    "    validation_data=(val_features_lstm, val_gender_labels),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=gender_callbacks,\n",
    "    class_weight=dict(enumerate(gender_weights))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812617a503aa478",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f271a80ba27a274",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_model.save('lstm_age_model.h5')\n",
    "gender_model.save('lstm_gender_model.h5')\n",
    "print(\"LSTM models saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782bde0a616e8a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e82d78d69948dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# After training the separate LSTM models, we can evaluate them together:\n",
    "print(\"Evaluating LSTM models...\")\n",
    "\n",
    "# Make predictions with both models\n",
    "age_predictions = np.argmax(age_model.predict(test_features_lstm), axis=1)\n",
    "gender_predictions = np.argmax(gender_model.predict(test_features_lstm), axis=1)\n",
    "\n",
    "# Calculate individual accuracies\n",
    "age_accuracy = np.mean(age_predictions == test_data['age_encoded'].values)\n",
    "gender_accuracy = np.mean(gender_predictions == test_data['gender_encoded'].values)\n",
    "\n",
    "# Calculate combined accuracy (both predictions correct)\n",
    "correct_both = np.logical_and(\n",
    "    age_predictions == test_data['age_encoded'].values,\n",
    "    gender_predictions == test_data['gender_encoded'].values\n",
    ")\n",
    "combined_accuracy = np.mean(correct_both)\n",
    "\n",
    "print(f\"Age Accuracy: {age_accuracy:.4f}\")\n",
    "print(f\"Gender Accuracy: {gender_accuracy:.4f}\")\n",
    "print(f\"Combined Accuracy (both correct): {combined_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b71477a7930fc9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Generate classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9df2c1eebd0144",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\nAge Classification Report:\")\n",
    "print(classification_report(test_data['age_encoded'].values, age_predictions, \n",
    "                         target_names=age_encoder.classes_))\n",
    "print(\"\\nGender Classification Report:\")\n",
    "print(classification_report(test_data['gender_encoded'].values, gender_predictions, \n",
    "                         target_names=gender_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8fdc31902a9d08",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339eedd689b579c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Age accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(age_history.history['accuracy'], label='Train Age Accuracy')\n",
    "plt.plot(age_history.history['val_accuracy'], label='Validation Age Accuracy')\n",
    "plt.title('LSTM Age Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Age loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(age_history.history['loss'], label='Train Age Loss')\n",
    "plt.plot(age_history.history['val_loss'], label='Validation Age Loss')\n",
    "plt.title('LSTM Age Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lstm_age_training_history.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualize training history for gender model\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gender accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(gender_history.history['accuracy'], label='Train Gender Accuracy')\n",
    "plt.plot(gender_history.history['val_accuracy'], label='Validation Gender Accuracy')\n",
    "plt.title('LSTM Gender Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Gender loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(gender_history.history['loss'], label='Train Gender Loss')\n",
    "plt.plot(gender_history.history['val_loss'], label='Validation Gender Loss')\n",
    "plt.title('LSTM Gender Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lstm_gender_training_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca410b1103a6624e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Example of how to load the model and use it for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443479341485d75b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_age_and_gender_with_lstm(image_path):\n",
    "    \"\"\"\n",
    "    Load pre-trained LSTM models and predict age and gender from an image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (age_range, gender) as strings\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import joblib\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from img2vec import rgb2emb\n",
    "    \n",
    "    # Check if the image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        return \"Error: Image not found\"\n",
    "    \n",
    "    # Load the models\n",
    "    try:\n",
    "        age_model = load_model('lstm_age_model.h5')\n",
    "        gender_model = load_model('lstm_gender_model.h5')\n",
    "    except Exception as e:\n",
    "        return f\"Error loading models: {str(e)}\"\n",
    "    \n",
    "    # Load the encoders\n",
    "    try:\n",
    "        age_encoder = joblib.load('age_encoder.pkl')\n",
    "        gender_encoder = joblib.load('gender_encoder.pkl')\n",
    "        scaler = joblib.load('feature_scaler.pkl')\n",
    "    except Exception as e:\n",
    "        return f\"Error loading encoders: {str(e)}\"\n",
    "    \n",
    "    # Extract features from the image\n",
    "    try:\n",
    "        # Convert to batch format (list with single image)\n",
    "        features = rgb2emb([image_path])\n",
    "        \n",
    "        # Scale features\n",
    "        features_scaled = scaler.transform(features)\n",
    "        \n",
    "        # Reshape for LSTM input\n",
    "        features_lstm = reshape_features_for_lstm(features_scaled, time_steps=16)\n",
    "        \n",
    "        # Make predictions\n",
    "        age_pred = np.argmax(age_model.predict(features_lstm), axis=1)[0]\n",
    "        gender_pred = np.argmax(gender_model.predict(features_lstm), axis=1)[0]\n",
    "        \n",
    "        # Convert numerical predictions to original labels\n",
    "        age_range = age_encoder.inverse_transform([age_pred])[0]\n",
    "        gender = gender_encoder.inverse_transform([gender_pred])[0]\n",
    "        \n",
    "        return (age_range, gender)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error during prediction: {str(e)}\"\n",
    "\n",
    "# Example usage:\n",
    "age_range, gender = predict_age_and_gender_with_lstm(\"../../img.jpg\")\n",
    "print(f\"Predicted Age Range: {age_range}\")\n",
    "print(f\"Predicted Gender: {gender}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
