{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from img2vec import rgb2flat\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 256"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T17:19:48.690683600Z",
     "start_time": "2025-02-12T17:19:39.154603300Z"
    }
   },
   "id": "b7fdfda1b28f7d93"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### read the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a63df6bf1d9882ce"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join('..', 'data', 'train.csv'))\n",
    "val_data = pd.read_csv(os.path.join('..', 'data', 'val.csv'))\n",
    "test_data = pd.read_csv(os.path.join('..', 'data', 'test.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T17:19:48.769320Z",
     "start_time": "2025-02-12T17:19:48.698407400Z"
    }
   },
   "id": "51d1d26e45f4b741"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### add the path of the images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d541bc891ff22bf2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         user_id  face_id                original_image        age gender  \\\n0    9855553@N08     1581  11658657103_4485e3f5ac_o.jpg  (60, 100)      m   \n1  114841417@N06      502  12059583524_606ca96139_o.jpg   (15, 20)      m   \n2   66870968@N06     1227  11326189206_e08bdf6dfd_o.jpg   (25, 32)      m   \n3    8187011@N06      988  11133041085_e2ee5e12cb_o.jpg     (0, 2)      u   \n4  114841417@N06      485  12059753735_7141b5443c_o.jpg   (15, 20)      f   \n\n                                            img_path  \n0  ..\\data\\faces\\9855553@N08\\coarse_tilt_aligned_...  \n1  ..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...  \n2  ..\\data\\faces\\66870968@N06\\coarse_tilt_aligned...  \n3  ..\\data\\faces\\8187011@N06\\coarse_tilt_aligned_...  \n4  ..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>face_id</th>\n      <th>original_image</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>img_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9855553@N08</td>\n      <td>1581</td>\n      <td>11658657103_4485e3f5ac_o.jpg</td>\n      <td>(60, 100)</td>\n      <td>m</td>\n      <td>..\\data\\faces\\9855553@N08\\coarse_tilt_aligned_...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114841417@N06</td>\n      <td>502</td>\n      <td>12059583524_606ca96139_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>m</td>\n      <td>..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>66870968@N06</td>\n      <td>1227</td>\n      <td>11326189206_e08bdf6dfd_o.jpg</td>\n      <td>(25, 32)</td>\n      <td>m</td>\n      <td>..\\data\\faces\\66870968@N06\\coarse_tilt_aligned...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8187011@N06</td>\n      <td>988</td>\n      <td>11133041085_e2ee5e12cb_o.jpg</td>\n      <td>(0, 2)</td>\n      <td>u</td>\n      <td>..\\data\\faces\\8187011@N06\\coarse_tilt_aligned_...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>114841417@N06</td>\n      <td>485</td>\n      <td>12059753735_7141b5443c_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>f</td>\n      <td>..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def construct_img_path(row):\n",
    "    return os.path.join(\"..\", \"data\", \"faces\", row['user_id'],\n",
    "                        \"coarse_tilt_aligned_face.\" + str(row['face_id']) + \".\" + row['original_image'])\n",
    "\n",
    "\n",
    "train_data['img_path'] = train_data.apply(construct_img_path, axis=1)\n",
    "val_data['img_path'] = val_data.apply(construct_img_path, axis=1)\n",
    "test_data['img_path'] = test_data.apply(construct_img_path, axis=1)\n",
    "train_data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T17:19:49.232660700Z",
     "start_time": "2025-02-12T17:19:48.773347900Z"
    }
   },
   "id": "7b1d46fc867cb10a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### add column for check if the image exists\n",
    "it will help us to detect if there is any missing image, or if there is any bug in the path construction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8df65de30e5e25a7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         user_id  face_id                original_image        age gender  \\\n0    9855553@N08     1581  11658657103_4485e3f5ac_o.jpg  (60, 100)      m   \n1  114841417@N06      502  12059583524_606ca96139_o.jpg   (15, 20)      m   \n2   66870968@N06     1227  11326189206_e08bdf6dfd_o.jpg   (25, 32)      m   \n3    8187011@N06      988  11133041085_e2ee5e12cb_o.jpg     (0, 2)      u   \n4  114841417@N06      485  12059753735_7141b5443c_o.jpg   (15, 20)      f   \n\n                                            img_path  img_exists  \n0  ..\\data\\faces\\9855553@N08\\coarse_tilt_aligned_...        True  \n1  ..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...        True  \n2  ..\\data\\faces\\66870968@N06\\coarse_tilt_aligned...        True  \n3  ..\\data\\faces\\8187011@N06\\coarse_tilt_aligned_...        True  \n4  ..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...        True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>face_id</th>\n      <th>original_image</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>img_path</th>\n      <th>img_exists</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9855553@N08</td>\n      <td>1581</td>\n      <td>11658657103_4485e3f5ac_o.jpg</td>\n      <td>(60, 100)</td>\n      <td>m</td>\n      <td>..\\data\\faces\\9855553@N08\\coarse_tilt_aligned_...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114841417@N06</td>\n      <td>502</td>\n      <td>12059583524_606ca96139_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>m</td>\n      <td>..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>66870968@N06</td>\n      <td>1227</td>\n      <td>11326189206_e08bdf6dfd_o.jpg</td>\n      <td>(25, 32)</td>\n      <td>m</td>\n      <td>..\\data\\faces\\66870968@N06\\coarse_tilt_aligned...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8187011@N06</td>\n      <td>988</td>\n      <td>11133041085_e2ee5e12cb_o.jpg</td>\n      <td>(0, 2)</td>\n      <td>u</td>\n      <td>..\\data\\faces\\8187011@N06\\coarse_tilt_aligned_...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>114841417@N06</td>\n      <td>485</td>\n      <td>12059753735_7141b5443c_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>f</td>\n      <td>..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['img_exists'] = train_data['img_path'].apply(os.path.exists)\n",
    "val_data['img_exists'] = val_data['img_path'].apply(os.path.exists)\n",
    "test_data['img_exists'] = test_data['img_path'].apply(os.path.exists)\n",
    "\n",
    "train_data.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c915be97d0fd9eb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age classes: ['(0, 2)' '(15, 20)' '(25, 32)' '(38, 43)' '(4, 6)' '(48, 53)' '(60, 100)'\n",
      " '(8, 23)']\n"
     ]
    },
    {
     "data": {
      "text/plain": "         user_id  face_id                original_image        age gender  \\\n0    9855553@N08     1581  11658657103_4485e3f5ac_o.jpg  (60, 100)      m   \n1  114841417@N06      502  12059583524_606ca96139_o.jpg   (15, 20)      m   \n2   66870968@N06     1227  11326189206_e08bdf6dfd_o.jpg   (25, 32)      m   \n3    8187011@N06      988  11133041085_e2ee5e12cb_o.jpg     (0, 2)      u   \n4  114841417@N06      485  12059753735_7141b5443c_o.jpg   (15, 20)      f   \n\n                                            img_path  img_exists  age_label  \n0  ..\\data\\faces\\9855553@N08\\coarse_tilt_aligned_...        True          6  \n1  ..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...        True          1  \n2  ..\\data\\faces\\66870968@N06\\coarse_tilt_aligned...        True          2  \n3  ..\\data\\faces\\8187011@N06\\coarse_tilt_aligned_...        True          0  \n4  ..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...        True          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>face_id</th>\n      <th>original_image</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>img_path</th>\n      <th>img_exists</th>\n      <th>age_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9855553@N08</td>\n      <td>1581</td>\n      <td>11658657103_4485e3f5ac_o.jpg</td>\n      <td>(60, 100)</td>\n      <td>m</td>\n      <td>..\\data\\faces\\9855553@N08\\coarse_tilt_aligned_...</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114841417@N06</td>\n      <td>502</td>\n      <td>12059583524_606ca96139_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>m</td>\n      <td>..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>66870968@N06</td>\n      <td>1227</td>\n      <td>11326189206_e08bdf6dfd_o.jpg</td>\n      <td>(25, 32)</td>\n      <td>m</td>\n      <td>..\\data\\faces\\66870968@N06\\coarse_tilt_aligned...</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8187011@N06</td>\n      <td>988</td>\n      <td>11133041085_e2ee5e12cb_o.jpg</td>\n      <td>(0, 2)</td>\n      <td>u</td>\n      <td>..\\data\\faces\\8187011@N06\\coarse_tilt_aligned_...</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>114841417@N06</td>\n      <td>485</td>\n      <td>12059753735_7141b5443c_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>f</td>\n      <td>..\\data\\faces\\114841417@N06\\coarse_tilt_aligne...</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Encode age labels\n",
    "age_encoder = LabelEncoder()\n",
    "train_data['age_label'] = age_encoder.fit_transform(train_data['age'])\n",
    "val_data['age_label'] = age_encoder.transform(val_data['age'])\n",
    "test_data['age_label'] = age_encoder.transform(test_data['age'])\n",
    "num_classes = len(age_encoder.classes_)\n",
    "print(\"Age classes:\", age_encoder.classes_)\n",
    "train_data.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13f972e81bf1aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter out any rows where the image doesn't exist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcb2fa7830f47cf8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data_filtered = train_data[train_data['img_exists'] == True]\n",
    "val_data_filtered = val_data[val_data['img_exists'] == True]\n",
    "test_data_filtered = test_data[test_data['img_exists'] == True]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "facd05e692b7b1f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define a generator function to process images in batches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3af64d1ee4038b96"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def image_batch_generator(image_paths, labels, batch_size):\n",
    "    num_samples = len(image_paths)\n",
    "    num_batches = math.ceil(num_samples / batch_size)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, num_samples)\n",
    "\n",
    "        batch_paths = image_paths[start_idx:end_idx]\n",
    "        batch_features = rgb2flat(batch_paths) / 255.0  # Normalize to [0,1]\n",
    "        batch_labels = labels[start_idx:end_idx]\n",
    "\n",
    "        yield batch_features, batch_labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T10:39:32.594540100Z",
     "start_time": "2025-02-26T10:39:32.563857200Z"
    }
   },
   "id": "613ac4858cc2e830"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract image paths and labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de85480f4cd99025"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_image_paths = train_data_filtered['img_path'].tolist()\n",
    "train_labels = train_data_filtered['age_label'].values\n",
    "\n",
    "val_image_paths = val_data_filtered['img_path'].tolist()\n",
    "val_labels = val_data_filtered['age_label'].values\n",
    "\n",
    "test_image_paths = test_data_filtered['img_path'].tolist()\n",
    "test_labels = test_data_filtered['age_label'].values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2fc8e2f5e6e670a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process a single batch to determine input shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afd81221629cef95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Processing a sample batch to determine input dimensions...\")\n",
    "sample_batch_size = min(10, len(train_image_paths))\n",
    "sample_paths = train_image_paths[:sample_batch_size]\n",
    "sample_batch = rgb2flat(sample_paths)\n",
    "input_shape = sample_batch.shape[1]\n",
    "print(f\"Input shape: {input_shape}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74d999019a500f03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de337a62f44c586"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(num_classes, activation='softmax', input_shape=(input_shape,))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f4a164009719c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model using batches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "def226d53aac2ea5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training the model...\")\n",
    "epochs = 10\n",
    "steps_per_epoch = math.ceil(len(train_image_paths) / batch_size)\n",
    "validation_steps = math.ceil(len(val_image_paths) / batch_size)\n",
    "\n",
    "# Custom training loop\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    # Training\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch_features, batch_labels in image_batch_generator(train_image_paths, train_labels, batch_size):\n",
    "        # Train on batch\n",
    "        batch_history = model.train_on_batch(\n",
    "            batch_features,\n",
    "            batch_labels,\n",
    "            reset_metrics=False\n",
    "        )\n",
    "\n",
    "        batch_loss, batch_acc = batch_history\n",
    "        train_loss += batch_loss\n",
    "        train_acc += batch_acc\n",
    "        batch_count += 1\n",
    "\n",
    "        print(f\"\\rBatch {batch_count}/{steps_per_epoch} - loss: {batch_loss:.4f} - accuracy: {batch_acc:.4f}\", end=\"\")\n",
    "\n",
    "    avg_train_loss = train_loss / batch_count\n",
    "    avg_train_acc = train_acc / batch_count\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(avg_train_acc)\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch_features, batch_labels in image_batch_generator(val_image_paths, val_labels, batch_size):\n",
    "        # Evaluate on batch\n",
    "        batch_val_loss, batch_val_acc = model.test_on_batch(\n",
    "            batch_features,\n",
    "            batch_labels,\n",
    "            reset_metrics=False\n",
    "        )\n",
    "\n",
    "        val_loss += batch_val_loss\n",
    "        val_acc += batch_val_acc\n",
    "        batch_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / batch_count\n",
    "    avg_val_acc = val_acc / batch_count\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(avg_val_acc)\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch {epoch + 1}: loss={avg_train_loss:.4f}, accuracy={avg_train_acc:.4f}, val_loss={avg_val_loss:.4f}, val_accuracy={avg_val_acc:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaa47ef25fe556a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the model on test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db63f493a1683170"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Evaluating the model on test data...\")\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "batch_count = 0\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for batch_features, batch_labels in image_batch_generator(test_image_paths, test_labels, batch_size):\n",
    "    # Evaluate on batch\n",
    "    batch_test_loss, batch_test_acc = model.test_on_batch(\n",
    "        batch_features,\n",
    "        batch_labels,\n",
    "        reset_metrics=False\n",
    "    )\n",
    "\n",
    "    # Get predictions for this batch\n",
    "    batch_preds = model.predict_on_batch(batch_features)\n",
    "    batch_pred_classes = np.argmax(batch_preds, axis=1)\n",
    "\n",
    "    all_predictions.extend(batch_pred_classes)\n",
    "    all_labels.extend(batch_labels)\n",
    "\n",
    "    test_loss += batch_test_loss\n",
    "    test_acc += batch_test_acc\n",
    "    batch_count += 1\n",
    "\n",
    "avg_test_loss = test_loss / batch_count\n",
    "avg_test_acc = test_acc / batch_count\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {avg_test_acc:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "414fc01e63806105"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd36e6294c8bf82d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=age_encoder.classes_,\n",
    "            yticklabels=age_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=age_encoder.classes_))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ed8e315739a638c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e21e8b64d196b50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('basic_softmax_age_classifier.h5')\n",
    "print(\"Model saved successfully.\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "197bae6e0a4ce665"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Function to predict age range for a new image\n",
    "def predict_age(image_path, model, age_encoder):\n",
    "    # Extract features using rgb2flat\n",
    "    features = rgb2flat([image_path])\n",
    "    # Normalize features\n",
    "    features = features / 255.0\n",
    "    # Make prediction\n",
    "    pred_probs = model.predict(features)[0]\n",
    "    # Get predicted class\n",
    "    pred_class = np.argmax(pred_probs)\n",
    "    # Convert to age range\n",
    "    pred_age_range = age_encoder.classes_[pred_class]\n",
    "    confidence = pred_probs[pred_class]\n",
    "\n",
    "    return pred_age_range, confidence\n",
    "\n",
    "# Example usage:\n",
    "# image_path = \"path/to/new/face/image.jpg\"\n",
    "# pred_age, confidence = predict_age(image_path, model, age_encoder)\n",
    "# print(f\"Predicted age range: {pred_age} with confidence {confidence:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T10:42:52.920560300Z",
     "start_time": "2025-02-26T10:42:52.769431200Z"
    }
   },
   "id": "a676b8e8ede7b14d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c706a072368c3614"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
