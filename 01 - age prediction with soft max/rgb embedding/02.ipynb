{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from img2vec import rgb2emb\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:09.736123800Z",
     "start_time": "2025-02-28T10:55:07.457940200Z"
    }
   },
   "id": "845b486670efa827"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:09.751547100Z",
     "start_time": "2025-02-28T10:55:09.736123800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef0468300ae56a68"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join('..', '..', 'data', 'train.csv'))\n",
    "val_data = pd.read_csv(os.path.join('..', '..', 'data', 'val.csv'))\n",
    "test_data = pd.read_csv(os.path.join('..', '..', 'data', 'test.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:09.783870500Z",
     "start_time": "2025-02-28T10:55:09.751547100Z"
    }
   },
   "id": "4f0f6a844c8192c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encode age labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0fbf38b5231c27e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age classes: ['(0, 2)' '(15, 20)' '(25, 32)' '(38, 43)' '(4, 6)' '(48, 53)' '(60, 100)'\n",
      " '(8, 23)']\n"
     ]
    }
   ],
   "source": [
    "age_encoder = LabelEncoder()\n",
    "train_data['age_label'] = age_encoder.fit_transform(train_data['age'])\n",
    "val_data['age_label'] = age_encoder.transform(val_data['age'])\n",
    "test_data['age_label'] = age_encoder.transform(test_data['age'])\n",
    "num_classes = len(age_encoder.classes_)\n",
    "print(\"Age classes:\", age_encoder.classes_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:09.805337600Z",
     "start_time": "2025-02-28T10:55:09.783870500Z"
    }
   },
   "id": "12c6733ff007c00f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the encoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3385a34d8800469"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age encoder saved successfully.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(age_encoder, 'age_encoder.pkl')\n",
    "print(\"Age encoder saved successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:09.863211400Z",
     "start_time": "2025-02-28T10:55:09.803261600Z"
    }
   },
   "id": "871ac10164b8884a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add image paths"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a634a085d5f03e9a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def construct_img_path(row):\n",
    "    return os.path.join(\"..\", \"..\", \"data\", \"faces\", row['user_id'],\n",
    "                        \"coarse_tilt_aligned_face.\" + str(row['face_id']) + \".\" + row['original_image'])\n",
    "\n",
    "train_data['img_path'] = train_data.apply(construct_img_path, axis=1)\n",
    "val_data['img_path'] = val_data.apply(construct_img_path, axis=1)\n",
    "test_data['img_path'] = test_data.apply(construct_img_path, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:10.007701400Z",
     "start_time": "2025-02-28T10:55:09.818931900Z"
    }
   },
   "id": "607148ae4bcf957e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check if images exist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d016a8227abffe3e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_data['img_exists'] = train_data['img_path'].apply(os.path.exists)\n",
    "val_data['img_exists'] = val_data['img_path'].apply(os.path.exists)\n",
    "test_data['img_exists'] = test_data['img_path'].apply(os.path.exists)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:10.683006600Z",
     "start_time": "2025-02-28T10:55:10.007701400Z"
    }
   },
   "id": "41aeddb8c258903d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter out any rows where the image doesn't exist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2da31554c89bfe8f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_data_filtered = train_data[train_data['img_exists'] == True]\n",
    "val_data_filtered = val_data[val_data['img_exists'] == True]\n",
    "test_data_filtered = test_data[test_data['img_exists'] == True]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:10.698688700Z",
     "start_time": "2025-02-28T10:55:10.686730400Z"
    }
   },
   "id": "7ab57cead8964597"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract image paths and labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e407f9502900def5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_image_paths = train_data_filtered['img_path'].tolist()\n",
    "train_labels = train_data_filtered['age_label'].values\n",
    "\n",
    "val_image_paths = val_data_filtered['img_path'].tolist()\n",
    "val_labels = val_data_filtered['age_label'].values\n",
    "\n",
    "test_image_paths = test_data_filtered['img_path'].tolist()\n",
    "test_labels = test_data_filtered['age_label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:10.714457400Z",
     "start_time": "2025-02-28T10:55:10.698688700Z"
    }
   },
   "id": "51a490149625d986"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define function that process features in batches and store them to avoid recomputation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee9693e8577e8b82"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def preprocess_and_save_features(image_paths, output_file, batch_size=64):\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading pre-processed features from {output_file}\")\n",
    "        return np.load(output_file)\n",
    "    \n",
    "    print(f\"Processing {len(image_paths)} images and saving to {output_file}\")\n",
    "    all_features = []\n",
    "    \n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{math.ceil(len(image_paths)/batch_size)}\")\n",
    "        batch_features = rgb2emb(batch_paths)\n",
    "        all_features.append(batch_features)\n",
    "    \n",
    "    all_features = np.vstack(all_features)\n",
    "    np.save(output_file, all_features)\n",
    "    return all_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:10.734604500Z",
     "start_time": "2025-02-28T10:55:10.714457400Z"
    }
   },
   "id": "cad2945b67e5b9c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process and save features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43dcace2616adc9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 11856 images and saving to train_features.npy\n",
      "Processing batch 1/186\n",
      "Processing batch 2/186\n",
      "Processing batch 3/186\n",
      "Processing batch 4/186\n",
      "Processing batch 5/186\n"
     ]
    }
   ],
   "source": [
    "train_features = preprocess_and_save_features(train_image_paths, 'train_features.npy')\n",
    "val_features = preprocess_and_save_features(val_image_paths, 'val_features.npy')\n",
    "test_features = preprocess_and_save_features(test_image_paths, 'test_features.npy')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:55:10.819723Z"
    }
   },
   "id": "8d609e762c70e636"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standardize features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "941d64c0e52e30c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "val_features_scaled = scaler.transform(val_features)\n",
    "test_features_scaled = scaler.transform(test_features)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2e9721bdb44b96d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the scaler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f7f3961c282531c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joblib.dump(scaler, 'feature_scaler.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bf3e765704a2a010"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define a simple softmax model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cadd81c1f5f4d2c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(num_classes, activation='softmax', input_shape=(train_features.shape[1],))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2192cee190c91935"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de455b483a341dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_features_scaled, train_labels,\n",
    "    validation_data=(val_features_scaled, val_labels),\n",
    "    epochs=30,\n",
    "    batch_size=batch_size,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f899eb1e92f85316"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89e27609865dd42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('softmax_age_classifier.h5')\n",
    "print(\"Model saved successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "eebb79a76147a427"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dccf170527cec3ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Evaluating the model on test data...\")\n",
    "test_loss, test_acc = model.evaluate(test_features_scaled, test_labels)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ea517ee225cddf77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95b430298f60e870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_features_scaled)\n",
    "test_pred_classes = np.argmax(test_predictions, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b63deba842304f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d4f82fb12952ae3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(test_labels, test_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=age_encoder.classes_,\n",
    "            yticklabels=age_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "97f1fa90dc78ca31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification report"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dee3d63459bc60c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_pred_classes, target_names=age_encoder.classes_))\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e8041a6f4ba05f18"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example of using the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d09685625d37f85e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('softmax_age_classifier.h5')\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Load the LabelEncoder\n",
    "age_encoder = joblib.load('age_encoder.pkl')\n",
    "print(\"Age encoder loaded successfully.\")\n",
    "\n",
    "# Load the scaler\n",
    "scaler = joblib.load('feature_scaler.pkl')\n",
    "print(\"Feature scaler loaded successfully.\")\n",
    "\n",
    "def predict_age(image_path, model, age_encoder, scaler):\n",
    "    \"\"\"\n",
    "    Predict the age range for a given face image.\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): Path to the image file\n",
    "    model: Trained Keras model\n",
    "    age_encoder: Trained LabelEncoder for age classes\n",
    "    scaler: Trained StandardScaler for feature normalization\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (predicted_age_range, confidence)\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: File {image_path} not found\")\n",
    "        return None, 0\n",
    "        \n",
    "    # Extract features\n",
    "    print(f\"Extracting features from {image_path}...\")\n",
    "    features = rgb2emb([image_path])\n",
    "    \n",
    "    # Check if feature extraction was successful\n",
    "    if features.size == 0:\n",
    "        print(\"Error: Feature extraction failed\")\n",
    "        return None, 0\n",
    "        \n",
    "    # Standardize features\n",
    "    print(\"Standardizing features...\")\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Make prediction\n",
    "    print(\"Making prediction...\")\n",
    "    pred_probs = model.predict(features_scaled, verbose=0)[0]\n",
    "    \n",
    "    # Get predicted class\n",
    "    pred_class = np.argmax(pred_probs)\n",
    "    \n",
    "    # Convert to age range\n",
    "    pred_age_range = age_encoder.classes_[pred_class]\n",
    "    confidence = pred_probs[pred_class]\n",
    "\n",
    "    return pred_age_range, confidence\n",
    "\n",
    "# Example usage with a sample image\n",
    "# Replace with an actual path to test\n",
    "sample_image_path = test_image_paths[0]  # Using the first test image as an example\n",
    "print(f\"Using sample image: {sample_image_path}\")\n",
    "\n",
    "# Make prediction\n",
    "pred_age, confidence = predict_age(sample_image_path, model, age_encoder, scaler)\n",
    "\n",
    "if pred_age is not None:\n",
    "    print(f\"Predicted age range: {pred_age} with confidence {confidence:.2f}\")\n",
    "    \n",
    "    # Display the image if possible\n",
    "    try:\n",
    "        from PIL import Image\n",
    "        img = Image.open(sample_image_path)\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Predicted: {pred_age} (Confidence: {confidence:.2f})\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not display image: {e}\")\n",
    "\n",
    "print(\"\\nCode for making predictions on new images:\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2aedef01ef573480"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
