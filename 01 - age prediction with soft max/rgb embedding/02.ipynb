{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from img2vec import rgb2emb\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:14.902750900Z",
     "start_time": "2025-02-28T10:52:05.822265600Z"
    }
   },
   "id": "845b486670efa827"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:14.916745700Z",
     "start_time": "2025-02-28T10:52:14.902750900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef0468300ae56a68"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join('..', '..', 'data', 'train.csv'))\n",
    "val_data = pd.read_csv(os.path.join('..', '..', 'data', 'val.csv'))\n",
    "test_data = pd.read_csv(os.path.join('..', '..', 'data', 'test.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:14.996157900Z",
     "start_time": "2025-02-28T10:52:14.916745700Z"
    }
   },
   "id": "4f0f6a844c8192c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add image paths"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a634a085d5f03e9a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def construct_img_path(row):\n",
    "    return os.path.join(\"..\", \"..\", \"data\", \"faces\", row['user_id'],\n",
    "                        \"coarse_tilt_aligned_face.\" + str(row['face_id']) + \".\" + row['original_image'])\n",
    "\n",
    "train_data['img_path'] = train_data.apply(construct_img_path, axis=1)\n",
    "val_data['img_path'] = val_data.apply(construct_img_path, axis=1)\n",
    "test_data['img_path'] = test_data.apply(construct_img_path, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:15.648849100Z",
     "start_time": "2025-02-28T10:52:14.996157900Z"
    }
   },
   "id": "607148ae4bcf957e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check if images exist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d016a8227abffe3e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_data['img_exists'] = train_data['img_path'].apply(os.path.exists)\n",
    "val_data['img_exists'] = val_data['img_path'].apply(os.path.exists)\n",
    "test_data['img_exists'] = test_data['img_path'].apply(os.path.exists)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:16.243245800Z",
     "start_time": "2025-02-28T10:52:15.220041900Z"
    }
   },
   "id": "41aeddb8c258903d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter out any rows where the image doesn't exist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2da31554c89bfe8f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_data_filtered = train_data[train_data['img_exists'] == True]\n",
    "val_data_filtered = val_data[val_data['img_exists'] == True]\n",
    "test_data_filtered = test_data[test_data['img_exists'] == True]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:16.263661300Z",
     "start_time": "2025-02-28T10:52:16.243245800Z"
    }
   },
   "id": "7ab57cead8964597"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encode age labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eec51a811017536"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age classes: ['(0, 2)' '(15, 20)' '(25, 32)' '(38, 43)' '(4, 6)' '(48, 53)' '(60, 100)'\n",
      " '(8, 23)']\n"
     ]
    }
   ],
   "source": [
    "age_encoder = LabelEncoder()\n",
    "train_data['age_label'] = age_encoder.fit_transform(train_data['age'])\n",
    "val_data['age_label'] = age_encoder.transform(val_data['age'])\n",
    "test_data['age_label'] = age_encoder.transform(test_data['age'])\n",
    "num_classes = len(age_encoder.classes_)\n",
    "print(\"Age classes:\", age_encoder.classes_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:16.321991500Z",
     "start_time": "2025-02-28T10:52:16.263661300Z"
    }
   },
   "id": "f38934b934076bc0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age encoder saved successfully.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(age_encoder, 'age_encoder.pkl')\n",
    "print(\"Age encoder saved successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:16.337636600Z",
     "start_time": "2025-02-28T10:52:16.274819300Z"
    }
   },
   "id": "1a908f071a102ffd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the encoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c98d24af91786ccf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract image paths and labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e407f9502900def5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age_label'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\projects\\ML\\final_project\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'age_label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m train_image_paths \u001B[38;5;241m=\u001B[39m train_data_filtered[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg_path\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m----> 2\u001B[0m train_labels \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_data_filtered\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mage_label\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m      4\u001B[0m val_image_paths \u001B[38;5;241m=\u001B[39m val_data_filtered[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg_path\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m      5\u001B[0m val_labels \u001B[38;5;241m=\u001B[39m val_data_filtered[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage_label\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n",
      "File \u001B[1;32m~\\projects\\ML\\final_project\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\projects\\ML\\final_project\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'age_label'"
     ]
    }
   ],
   "source": [
    "train_image_paths = train_data_filtered['img_path'].tolist()\n",
    "train_labels = train_data_filtered['age_label'].values\n",
    "\n",
    "val_image_paths = val_data_filtered['img_path'].tolist()\n",
    "val_labels = val_data_filtered['age_label'].values\n",
    "\n",
    "test_image_paths = test_data_filtered['img_path'].tolist()\n",
    "test_labels = test_data_filtered['age_label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:17.533790200Z",
     "start_time": "2025-02-28T10:52:16.290512600Z"
    }
   },
   "id": "51a490149625d986"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define function that process features in batches and store them to avoid recomputation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee9693e8577e8b82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_and_save_features(image_paths, output_file, batch_size=64):\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading pre-processed features from {output_file}\")\n",
    "        return np.load(output_file)\n",
    "    \n",
    "    print(f\"Processing {len(image_paths)} images and saving to {output_file}\")\n",
    "    all_features = []\n",
    "    \n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{math.ceil(len(image_paths)/batch_size)}\")\n",
    "        batch_features = rgb2emb(batch_paths)\n",
    "        all_features.append(batch_features)\n",
    "    \n",
    "    all_features = np.vstack(all_features)\n",
    "    np.save(output_file, all_features)\n",
    "    return all_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.533790200Z"
    }
   },
   "id": "cad2945b67e5b9c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process and save features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43dcace2616adc9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features = preprocess_and_save_features(train_image_paths, 'train_features.npy')\n",
    "val_features = preprocess_and_save_features(val_image_paths, 'val_features.npy')\n",
    "test_features = preprocess_and_save_features(test_image_paths, 'test_features.npy')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.533790200Z"
    }
   },
   "id": "8d609e762c70e636"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standardize features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "941d64c0e52e30c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "val_features_scaled = scaler.transform(val_features)\n",
    "test_features_scaled = scaler.transform(test_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.533790200Z"
    }
   },
   "id": "2e9721bdb44b96d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the scaler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f7f3961c282531c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joblib.dump(scaler, 'feature_scaler.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.533790200Z"
    }
   },
   "id": "bf3e765704a2a010"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define a simple softmax model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cadd81c1f5f4d2c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(num_classes, activation='softmax', input_shape=(train_features.shape[1],))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.550125900Z"
    }
   },
   "id": "2192cee190c91935"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de455b483a341dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_features_scaled, train_labels,\n",
    "    validation_data=(val_features_scaled, val_labels),\n",
    "    epochs=30,\n",
    "    batch_size=batch_size,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.552143200Z"
    }
   },
   "id": "f899eb1e92f85316"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89e27609865dd42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('softmax_age_classifier.h5')\n",
    "print(\"Model saved successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.554149900Z"
    }
   },
   "id": "eebb79a76147a427"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dccf170527cec3ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Evaluating the model on test data...\")\n",
    "test_loss, test_acc = model.evaluate(test_features_scaled, test_labels)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.556155Z"
    }
   },
   "id": "ea517ee225cddf77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95b430298f60e870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_features_scaled)\n",
    "test_pred_classes = np.argmax(test_predictions, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.556155Z"
    }
   },
   "id": "b63deba842304f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d4f82fb12952ae3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(test_labels, test_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=age_encoder.classes_,\n",
    "            yticklabels=age_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.556155Z"
    }
   },
   "id": "97f1fa90dc78ca31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification report"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dee3d63459bc60c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_pred_classes, target_names=age_encoder.classes_))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.558160100Z"
    }
   },
   "id": "e8041a6f4ba05f18"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example of using the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d09685625d37f85e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('softmax_age_classifier.h5')\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Load the LabelEncoder\n",
    "age_encoder = joblib.load('age_encoder.pkl')\n",
    "print(\"Age encoder loaded successfully.\")\n",
    "\n",
    "# Load the scaler\n",
    "scaler = joblib.load('feature_scaler.pkl')\n",
    "print(\"Feature scaler loaded successfully.\")\n",
    "\n",
    "def predict_age(image_path, model, age_encoder, scaler):\n",
    "    \"\"\"\n",
    "    Predict the age range for a given face image.\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): Path to the image file\n",
    "    model: Trained Keras model\n",
    "    age_encoder: Trained LabelEncoder for age classes\n",
    "    scaler: Trained StandardScaler for feature normalization\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (predicted_age_range, confidence)\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: File {image_path} not found\")\n",
    "        return None, 0\n",
    "        \n",
    "    # Extract features\n",
    "    print(f\"Extracting features from {image_path}...\")\n",
    "    features = rgb2emb([image_path])\n",
    "    \n",
    "    # Check if feature extraction was successful\n",
    "    if features.size == 0:\n",
    "        print(\"Error: Feature extraction failed\")\n",
    "        return None, 0\n",
    "        \n",
    "    # Standardize features\n",
    "    print(\"Standardizing features...\")\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Make prediction\n",
    "    print(\"Making prediction...\")\n",
    "    pred_probs = model.predict(features_scaled, verbose=0)[0]\n",
    "    \n",
    "    # Get predicted class\n",
    "    pred_class = np.argmax(pred_probs)\n",
    "    \n",
    "    # Convert to age range\n",
    "    pred_age_range = age_encoder.classes_[pred_class]\n",
    "    confidence = pred_probs[pred_class]\n",
    "\n",
    "    return pred_age_range, confidence\n",
    "\n",
    "# Example usage with a sample image\n",
    "# Replace with an actual path to test\n",
    "sample_image_path = test_image_paths[0]  # Using the first test image as an example\n",
    "print(f\"Using sample image: {sample_image_path}\")\n",
    "\n",
    "# Make prediction\n",
    "pred_age, confidence = predict_age(sample_image_path, model, age_encoder, scaler)\n",
    "\n",
    "if pred_age is not None:\n",
    "    print(f\"Predicted age range: {pred_age} with confidence {confidence:.2f}\")\n",
    "    \n",
    "    # Display the image if possible\n",
    "    try:\n",
    "        from PIL import Image\n",
    "        img = Image.open(sample_image_path)\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Predicted: {pred_age} (Confidence: {confidence:.2f})\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not display image: {e}\")\n",
    "\n",
    "print(\"\\nCode for making predictions on new images:\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-28T10:52:17.558160100Z"
    }
   },
   "id": "2aedef01ef573480"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
