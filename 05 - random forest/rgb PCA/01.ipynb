{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:40.165595Z",
     "start_time": "2025-03-01T18:22:40.151763Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from img2vec import rgb2flatPCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "\n",
    "# Define the batch size for data processing\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### read the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b15fd793aa68cfe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join('..', '..', 'data', 'train.csv'))\n",
    "val_data = pd.read_csv(os.path.join('..', '..', 'data', 'val.csv'))\n",
    "test_data = pd.read_csv(os.path.join('..', '..', 'data', 'test.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:43.946011Z",
     "start_time": "2025-03-01T18:22:40.164974Z"
    }
   },
   "id": "56785ea73c90d66c",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "### add the path of the images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70e74861622b690d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         user_id  face_id                original_image        age gender  \\\n0    9855553@N08     1581  11658657103_4485e3f5ac_o.jpg  (60, 100)      m   \n1  114841417@N06      502  12059583524_606ca96139_o.jpg   (15, 20)      m   \n2   66870968@N06     1227  11326189206_e08bdf6dfd_o.jpg   (25, 32)      m   \n3    8187011@N06      988  11133041085_e2ee5e12cb_o.jpg     (0, 2)      u   \n4  114841417@N06      485  12059753735_7141b5443c_o.jpg   (15, 20)      f   \n\n                                            img_path  \n0  ../../data/faces/9855553@N08/coarse_tilt_align...  \n1  ../../data/faces/114841417@N06/coarse_tilt_ali...  \n2  ../../data/faces/66870968@N06/coarse_tilt_alig...  \n3  ../../data/faces/8187011@N06/coarse_tilt_align...  \n4  ../../data/faces/114841417@N06/coarse_tilt_ali...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>face_id</th>\n      <th>original_image</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>img_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9855553@N08</td>\n      <td>1581</td>\n      <td>11658657103_4485e3f5ac_o.jpg</td>\n      <td>(60, 100)</td>\n      <td>m</td>\n      <td>../../data/faces/9855553@N08/coarse_tilt_align...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114841417@N06</td>\n      <td>502</td>\n      <td>12059583524_606ca96139_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>m</td>\n      <td>../../data/faces/114841417@N06/coarse_tilt_ali...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>66870968@N06</td>\n      <td>1227</td>\n      <td>11326189206_e08bdf6dfd_o.jpg</td>\n      <td>(25, 32)</td>\n      <td>m</td>\n      <td>../../data/faces/66870968@N06/coarse_tilt_alig...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8187011@N06</td>\n      <td>988</td>\n      <td>11133041085_e2ee5e12cb_o.jpg</td>\n      <td>(0, 2)</td>\n      <td>u</td>\n      <td>../../data/faces/8187011@N06/coarse_tilt_align...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>114841417@N06</td>\n      <td>485</td>\n      <td>12059753735_7141b5443c_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>f</td>\n      <td>../../data/faces/114841417@N06/coarse_tilt_ali...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def construct_img_path(row):\n",
    "    return os.path.join(\"..\", \"..\", \"data\", \"faces\", row['user_id'],\n",
    "                        \"coarse_tilt_aligned_face.\" + str(row['face_id']) + \".\" + row['original_image'])\n",
    "\n",
    "\n",
    "train_data['img_path'] = train_data.apply(construct_img_path, axis=1)\n",
    "val_data['img_path'] = val_data.apply(construct_img_path, axis=1)\n",
    "test_data['img_path'] = test_data.apply(construct_img_path, axis=1)\n",
    "train_data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:44.076855Z",
     "start_time": "2025-03-01T18:22:43.947720Z"
    }
   },
   "id": "aa8b437ad6f06287",
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### add column for check if the image exists\n",
    "it will help us to detect if there is any missing image, or if there is any bug in the path construction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cf861051088899c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         user_id  face_id                original_image        age gender  \\\n0    9855553@N08     1581  11658657103_4485e3f5ac_o.jpg  (60, 100)      m   \n1  114841417@N06      502  12059583524_606ca96139_o.jpg   (15, 20)      m   \n2   66870968@N06     1227  11326189206_e08bdf6dfd_o.jpg   (25, 32)      m   \n3    8187011@N06      988  11133041085_e2ee5e12cb_o.jpg     (0, 2)      u   \n4  114841417@N06      485  12059753735_7141b5443c_o.jpg   (15, 20)      f   \n\n                                            img_path  img_exists  \n0  ../../data/faces/9855553@N08/coarse_tilt_align...        True  \n1  ../../data/faces/114841417@N06/coarse_tilt_ali...        True  \n2  ../../data/faces/66870968@N06/coarse_tilt_alig...        True  \n3  ../../data/faces/8187011@N06/coarse_tilt_align...        True  \n4  ../../data/faces/114841417@N06/coarse_tilt_ali...        True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>face_id</th>\n      <th>original_image</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>img_path</th>\n      <th>img_exists</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9855553@N08</td>\n      <td>1581</td>\n      <td>11658657103_4485e3f5ac_o.jpg</td>\n      <td>(60, 100)</td>\n      <td>m</td>\n      <td>../../data/faces/9855553@N08/coarse_tilt_align...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114841417@N06</td>\n      <td>502</td>\n      <td>12059583524_606ca96139_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>m</td>\n      <td>../../data/faces/114841417@N06/coarse_tilt_ali...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>66870968@N06</td>\n      <td>1227</td>\n      <td>11326189206_e08bdf6dfd_o.jpg</td>\n      <td>(25, 32)</td>\n      <td>m</td>\n      <td>../../data/faces/66870968@N06/coarse_tilt_alig...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8187011@N06</td>\n      <td>988</td>\n      <td>11133041085_e2ee5e12cb_o.jpg</td>\n      <td>(0, 2)</td>\n      <td>u</td>\n      <td>../../data/faces/8187011@N06/coarse_tilt_align...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>114841417@N06</td>\n      <td>485</td>\n      <td>12059753735_7141b5443c_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>f</td>\n      <td>../../data/faces/114841417@N06/coarse_tilt_ali...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['img_exists'] = train_data['img_path'].apply(os.path.exists)\n",
    "val_data['img_exists'] = val_data['img_path'].apply(os.path.exists)\n",
    "test_data['img_exists'] = test_data['img_path'].apply(os.path.exists)\n",
    "\n",
    "train_data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:45.385480Z",
     "start_time": "2025-03-01T18:22:44.075197Z"
    }
   },
   "id": "611859bd0832e25b",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_age classes: ['f_(0, 2)' 'f_(15, 20)' 'f_(25, 32)' 'f_(38, 43)' 'f_(4, 6)' 'f_(48, 53)'\n",
      " 'f_(60, 100)' 'f_(8, 23)' 'm_(0, 2)' 'm_(15, 20)' 'm_(25, 32)'\n",
      " 'm_(38, 43)' 'm_(4, 6)' 'm_(48, 53)' 'm_(60, 100)' 'm_(8, 23)' 'u_(0, 2)'\n",
      " 'u_(25, 32)' 'u_(60, 100)' 'u_(8, 23)']\n"
     ]
    },
    {
     "data": {
      "text/plain": "         user_id  face_id                original_image        age gender  \\\n0    9855553@N08     1581  11658657103_4485e3f5ac_o.jpg  (60, 100)      m   \n1  114841417@N06      502  12059583524_606ca96139_o.jpg   (15, 20)      m   \n2   66870968@N06     1227  11326189206_e08bdf6dfd_o.jpg   (25, 32)      m   \n3    8187011@N06      988  11133041085_e2ee5e12cb_o.jpg     (0, 2)      u   \n4  114841417@N06      485  12059753735_7141b5443c_o.jpg   (15, 20)      f   \n\n                                            img_path  img_exists  \\\n0  ../../data/faces/9855553@N08/coarse_tilt_align...        True   \n1  ../../data/faces/114841417@N06/coarse_tilt_ali...        True   \n2  ../../data/faces/66870968@N06/coarse_tilt_alig...        True   \n3  ../../data/faces/8187011@N06/coarse_tilt_align...        True   \n4  ../../data/faces/114841417@N06/coarse_tilt_ali...        True   \n\n   gender_age_label  \n0                14  \n1                 9  \n2                10  \n3                16  \n4                 1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>face_id</th>\n      <th>original_image</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>img_path</th>\n      <th>img_exists</th>\n      <th>gender_age_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9855553@N08</td>\n      <td>1581</td>\n      <td>11658657103_4485e3f5ac_o.jpg</td>\n      <td>(60, 100)</td>\n      <td>m</td>\n      <td>../../data/faces/9855553@N08/coarse_tilt_align...</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114841417@N06</td>\n      <td>502</td>\n      <td>12059583524_606ca96139_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>m</td>\n      <td>../../data/faces/114841417@N06/coarse_tilt_ali...</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>66870968@N06</td>\n      <td>1227</td>\n      <td>11326189206_e08bdf6dfd_o.jpg</td>\n      <td>(25, 32)</td>\n      <td>m</td>\n      <td>../../data/faces/66870968@N06/coarse_tilt_alig...</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8187011@N06</td>\n      <td>988</td>\n      <td>11133041085_e2ee5e12cb_o.jpg</td>\n      <td>(0, 2)</td>\n      <td>u</td>\n      <td>../../data/faces/8187011@N06/coarse_tilt_align...</td>\n      <td>True</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>114841417@N06</td>\n      <td>485</td>\n      <td>12059753735_7141b5443c_o.jpg</td>\n      <td>(15, 20)</td>\n      <td>f</td>\n      <td>../../data/faces/114841417@N06/coarse_tilt_ali...</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_gender_age(train_data, val_data, test_data):\n",
    "    \"\"\"Encodes gender and age combinations into a single label, handling unseen labels.\"\"\"\n",
    "\n",
    "    train_data['gender_age_combined'] = train_data['gender'].astype(str) + '_' + train_data['age'].astype(str)\n",
    "    val_data['gender_age_combined'] = val_data['gender'].astype(str) + '_' + val_data['age'].astype(str)\n",
    "    test_data['gender_age_combined'] = test_data['gender'].astype(str) + '_' + test_data['age'].astype(str)\n",
    "\n",
    "    gender_age_encoder = LabelEncoder()\n",
    "    train_data['gender_age_label'] = gender_age_encoder.fit_transform(train_data['gender_age_combined'])\n",
    "\n",
    "    # Function to handle unseen labels\n",
    "    def transform_with_unknown(data, encoder):\n",
    "        known_classes = set(encoder.classes_)\n",
    "        data['gender_age_label'] = data['gender_age_combined'].apply(\n",
    "            lambda x: encoder.transform([x])[0] if x in known_classes else -1\n",
    "        ) # assign -1 to unseen label.\n",
    "        return data\n",
    "\n",
    "    val_data = transform_with_unknown(val_data, gender_age_encoder)\n",
    "    test_data = transform_with_unknown(test_data, gender_age_encoder)\n",
    "\n",
    "    num_classes = len(gender_age_encoder.classes_)\n",
    "\n",
    "    train_data.drop('gender_age_combined', axis=1, inplace=True)\n",
    "    val_data.drop('gender_age_combined', axis=1, inplace=True)\n",
    "    test_data.drop('gender_age_combined', axis=1, inplace=True)\n",
    "\n",
    "    return train_data, val_data, test_data, num_classes, gender_age_encoder\n",
    "\n",
    "train_data, val_data, test_data, num_classes, gender_age_encoder = encode_gender_age(train_data, val_data, test_data)\n",
    "\n",
    "num_classes = len(gender_age_encoder.classes_)\n",
    "print(\"gender_age classes:\", gender_age_encoder.classes_)\n",
    "train_data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:45.774140Z",
     "start_time": "2025-03-01T18:22:45.388729Z"
    }
   },
   "id": "26fd37d98537dabc",
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter out any rows where the image doesn't exist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b299c694d70b4e89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_filtered = train_data[train_data['img_exists'] == True]\n",
    "val_data_filtered = val_data[val_data['img_exists'] == True]\n",
    "test_data_filtered = test_data[test_data['img_exists'] == True]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:45.850361Z",
     "start_time": "2025-03-01T18:22:45.780722Z"
    }
   },
   "id": "87b13df392ccc16a",
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define a generator function to process images in batches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcdf27caf31c2d30"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def image_batch_generator(image_paths, labels, batch_size):\n",
    "    num_samples = len(image_paths)\n",
    "    num_batches = math.ceil(num_samples / batch_size)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, num_samples)\n",
    "\n",
    "        batch_paths = image_paths[start_idx:end_idx]\n",
    "        batch_features = rgb2flatPCA(batch_paths) / 255.0  # Normalize to [0,1]\n",
    "        batch_labels = labels[start_idx:end_idx]\n",
    "\n",
    "        yield batch_features, batch_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:45.851728Z",
     "start_time": "2025-03-01T18:22:45.806116Z"
    }
   },
   "id": "c1f226a0f087eb05",
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract image paths and labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7489c229253eb527"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_image_paths = train_data_filtered['img_path'].tolist()\n",
    "train_labels = train_data_filtered['gender_age_label'].values\n",
    "\n",
    "val_image_paths = val_data_filtered['img_path'].tolist()\n",
    "val_labels = val_data_filtered['gender_age_label'].values\n",
    "\n",
    "test_image_paths = test_data_filtered['img_path'].tolist()\n",
    "test_labels = test_data_filtered['gender_age_label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:45.853075Z",
     "start_time": "2025-03-01T18:22:45.813834Z"
    }
   },
   "id": "752703a149f5ca6a",
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print dataset sizes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "457e8304b54d5aca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 11856\n",
      "Validation samples: 2964\n",
      "Test samples: 3731\n",
      "Number of classes: 20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_image_paths)}\")\n",
    "print(f\"Validation samples: {len(val_image_paths)}\")\n",
    "print(f\"Test samples: {len(test_image_paths)}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:45.894624Z",
     "start_time": "2025-03-01T18:22:45.830243Z"
    }
   },
   "id": "a587aac28a637cb7",
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract features for training and validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "982a15987fc0dc4c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for training data...\n",
      "Processing all 11856 training samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features for training data...\")\n",
    "print(f\"Processing all {len(train_image_paths)} training samples\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:45.974896Z",
     "start_time": "2025-03-01T18:22:45.838679Z"
    }
   },
   "id": "e1d25bd326100df3",
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define a function to extract features in batches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f844c248193564a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_features_in_batches(image_paths, batch_size=64):\n",
    "    \"\"\"Extract features from images in batches to manage memory.\"\"\"\n",
    "    num_samples = len(image_paths)\n",
    "    num_batches = math.ceil(num_samples / batch_size)\n",
    "    all_features = []\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, num_samples)\n",
    "        \n",
    "        print(f\"\\rProcessing batch {i+1}/{num_batches}\", end=\"\")\n",
    "        \n",
    "        batch_paths = image_paths[start_idx:end_idx]\n",
    "        batch_features = rgb2flatPCA(batch_paths) / 255.0  # Normalize to [0,1]\n",
    "        \n",
    "        all_features.append(batch_features)\n",
    "    \n",
    "    print(\"\\nFeature extraction complete.\")\n",
    "    return np.vstack(all_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:22:45.978902Z",
     "start_time": "2025-03-01T18:22:45.851534Z"
    }
   },
   "id": "c35df22d363741e4",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/47"
     ]
    }
   ],
   "source": [
    "X_train = extract_features_in_batches(train_image_paths, batch_size=batch_size)\n",
    "y_train = train_labels\n",
    "\n",
    "print(\"Extracting features for validation data...\")\n",
    "print(f\"Processing all {len(val_image_paths)} validation samples\")\n",
    "\n",
    "X_val = extract_features_in_batches(val_image_paths, batch_size=batch_size)\n",
    "y_val = val_labels\n",
    "\n",
    "\n",
    "print(\"Creating and training RandomForestClassifier model...\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-01T18:22:45.859852Z"
    }
   },
   "id": "127a36687e189488",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a pipeline with scaling and RandomeForest\n",
    "This is much more memory efficient for large datasets\n",
    "Create a pipeline that scales data (optional for RF) and then trains a RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4362d975b8663eff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scaling can be useful even though RF doesn't strictly require it\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=100,           # Number of trees in the forest\n",
    "        criterion='gini',           # Criterion to measure split quality; can also use 'entropy'\n",
    "        max_depth=None,             # Expand nodes until all leaves are pure or until minimum sample split\n",
    "        class_weight='balanced',    # Adjust weights inversely proportional to class frequencies\n",
    "        random_state=42,            # For reproducibility\n",
    "        verbose=1,                  # Controls verbosity during training\n",
    "        n_jobs=-1                   # Use all available cores for parallel processing\n",
    "    ))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "da5d6cb5d433c265",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### define the model and train it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45316f6a60e23286"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Fit the pipeline directly\n",
    "pipeline.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "39f716f3e65b137",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the model on test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82cc85077ba09230"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Extract features for test data\n",
    "print(\"Extracting features for test data...\")\n",
    "print(f\"Processing all {len(test_image_paths)} test samples\")\n",
    "\n",
    "X_test = extract_features_in_batches(test_image_paths, batch_size=batch_size)\n",
    "y_test = test_labels\n",
    "\n",
    "# Evaluate on test data\n",
    "test_preds = model.predict(X_test)  # Use X_test instead of test_data\n",
    "test_accuracy = accuracy_score(y_test, test_preds)  # Use y_test instead of test_data\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "97bc5972922fe43a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93915f457e82f37f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "\n",
    "# Set up figure size\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a heatmap without masking zero values for better visualization\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', linewidths=0.5, \n",
    "            xticklabels=gender_age_encoder.classes_,\n",
    "            yticklabels=gender_age_encoder.classes_)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "\n",
    "# Improve layout and save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300)  # Higher DPI for better quality\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1323d9ca7917c37a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification report"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2f37397c17cd36"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Get the unique classes in your test data\n",
    "unique_classes = np.unique(y_test)\n",
    "\n",
    "# Generate classification report using the labels parameter\n",
    "report = classification_report(\n",
    "    y_test, \n",
    "    test_preds, \n",
    "    labels=unique_classes,\n",
    "    target_names=[gender_age_encoder.classes_[i] for i in unique_classes],\n",
    "    zero_division=0  # Handles the division by zero error by setting precision and recall to 0\n",
    ")\n",
    "\n",
    "# Print the classification report with better formatting\n",
    "print(\"=\" * 50)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\" * 50)\n",
    "print(report)\n",
    "print(\"=\" * 50)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3944bb25d1d10f93",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f52ccb640073a94f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dump(model, 'RF_gray_gender_age_classifier.joblib')\n",
    "dump(gender_age_encoder, 'gender_age_encoder.joblib')\n",
    "print(\"Model saved successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c92999e625025a28",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to predict gender_age range for a new image\n",
    "def predict_gender_age(image_path, model, gender_age_encoder):\n",
    "    \"\"\"Predict gender and age for a given face image.\"\"\"\n",
    "    # Extract features\n",
    "    features = rgb2flatPCA([image_path]) / 255.0\n",
    "    \n",
    "    # Apply the same scaling used during training (if using a pipeline with StandardScaler)\n",
    "    if hasattr(model, 'named_steps') and 'scaler' in model.named_steps:\n",
    "        features = model.named_steps['scaler'].transform(features)\n",
    "    \n",
    "    # Make prediction\n",
    "    pred_class = model.predict(features)[0]\n",
    "    \n",
    "    # Get class probabilities if available\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        pred_probs = model.predict_proba(features)[0]\n",
    "        confidence = pred_probs[pred_class]\n",
    "    else:\n",
    "        # For RandomForestClassifier without calibration, we can't get probabilities\n",
    "        # Use decision function instead as a rough proxy for confidence\n",
    "        decision_values = model.decision_function(features)\n",
    "        # Normalize to [0, 1] range roughly\n",
    "        confidence = 1 / (1 + np.exp(-np.abs(decision_values[0][pred_class])))\n",
    "    \n",
    "    # Convert to gender_age range\n",
    "    pred_gender_age_range = gender_age_encoder.classes_[pred_class]\n",
    "    \n",
    "    return pred_gender_age_range, confidence\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "# Load the model\n",
    "image_path = \"path/to/new/face/image.jpg\"\n",
    "model = load('linear_svc_gender_age_classifier.joblib')\n",
    "gender_age_encoder = load('gender_age_encoder.joblib')\n",
    "\n",
    "# Make prediction\n",
    "pred_gender_age, confidence = predict_gender_age(image_path, model, gender_age_encoder)\n",
    "print(f\"Predicted gender_age range: {pred_gender_age} with confidence {confidence:.2f}\")\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cc36e0b0e3a191d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c8174829fb103b46",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
