{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "\n",
    "# Define the batch size for data processing\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf67410f652b98c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba693e7da77017",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-01T18:30:24.581526Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join('..', '..', 'data', 'train.csv'))\n",
    "val_data = pd.read_csv(os.path.join('..', '..', 'data', 'val.csv'))\n",
    "test_data = pd.read_csv(os.path.join('..', '..', 'data', 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bca6182fbb46bc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### add the path of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bde55648f6cbcf",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-01T18:30:24.654332Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_img_path(row):\n",
    "    return os.path.join(\"..\", \"..\", \"data\", \"faces\", row['user_id'],\n",
    "                        \"coarse_tilt_aligned_face.\" + str(row['face_id']) + \".\" + row['original_image'])\n",
    "\n",
    "\n",
    "train_data['img_path'] = train_data.apply(construct_img_path, axis=1)\n",
    "val_data['img_path'] = val_data.apply(construct_img_path, axis=1)\n",
    "test_data['img_path'] = test_data.apply(construct_img_path, axis=1)\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ccbaf87304f93f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### add column for check if the image exists\n",
    "it will help us to detect if there is any missing image, or if there is any bug in the path construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c493e5d73810fb1",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-01T18:30:24.743956Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['img_exists'] = train_data['img_path'].apply(os.path.exists)\n",
    "val_data['img_exists'] = val_data['img_path'].apply(os.path.exists)\n",
    "test_data['img_exists'] = test_data['img_path'].apply(os.path.exists)\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d940523377f8b25",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-01T18:30:25.079776Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_gender_age(train_data, val_data, test_data):\n",
    "    \"\"\"Encodes gender and age combinations into a single label, handling unseen labels.\"\"\"\n",
    "\n",
    "    train_data['gender_age_combined'] = train_data['gender'].astype(str) + '_' + train_data['age'].astype(str)\n",
    "    val_data['gender_age_combined'] = val_data['gender'].astype(str) + '_' + val_data['age'].astype(str)\n",
    "    test_data['gender_age_combined'] = test_data['gender'].astype(str) + '_' + test_data['age'].astype(str)\n",
    "\n",
    "    gender_age_encoder = LabelEncoder()\n",
    "    train_data['gender_age_label'] = gender_age_encoder.fit_transform(train_data['gender_age_combined'])\n",
    "\n",
    "    # Function to handle unseen labels\n",
    "    def transform_with_unknown(data, encoder):\n",
    "        known_classes = set(encoder.classes_)\n",
    "        data['gender_age_label'] = data['gender_age_combined'].apply(\n",
    "            lambda x: encoder.transform([x])[0] if x in known_classes else -1\n",
    "        ) # assign -1 to unseen label.\n",
    "        return data\n",
    "\n",
    "    val_data = transform_with_unknown(val_data, gender_age_encoder)\n",
    "    test_data = transform_with_unknown(test_data, gender_age_encoder)\n",
    "\n",
    "    num_classes = len(gender_age_encoder.classes_)\n",
    "\n",
    "    train_data.drop('gender_age_combined', axis=1, inplace=True)\n",
    "    val_data.drop('gender_age_combined', axis=1, inplace=True)\n",
    "    test_data.drop('gender_age_combined', axis=1, inplace=True)\n",
    "\n",
    "    return train_data, val_data, test_data, num_classes, gender_age_encoder\n",
    "\n",
    "train_data, val_data, test_data, num_classes, gender_age_encoder = encode_gender_age(train_data, val_data, test_data)\n",
    "\n",
    "num_classes = len(gender_age_encoder.classes_)\n",
    "print(\"gender_age classes:\", gender_age_encoder.classes_)\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967a7d1e840d381",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Filter out any rows where the image doesn't exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db58f446ed7ed8d",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-01T18:30:25.432511Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_filtered = train_data[train_data['img_exists'] == True]\n",
    "val_data_filtered = val_data[val_data['img_exists'] == True]\n",
    "test_data_filtered = test_data[test_data['img_exists'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10479fab31f4f172",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Define a generator function to process images in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b839edec59102f",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-01T18:30:25.439386Z"
    }
   },
   "outputs": [],
   "source": [
    "from img2vec import gray2emb\n",
    "\n",
    "\n",
    "def image_batch_generator(image_paths, labels, batch_size):\n",
    "    num_samples = len(image_paths)\n",
    "    num_batches = math.ceil(num_samples / batch_size)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, num_samples)\n",
    "\n",
    "        batch_paths = image_paths[start_idx:end_idx]\n",
    "        batch_features = gray2emb(batch_paths) / 255.0  # Normalize to [0,1]\n",
    "        batch_labels = labels[start_idx:end_idx]\n",
    "\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da59c50f0be89fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Extract image paths and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b28c169da16536",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "train_image_paths = train_data_filtered['img_path'].tolist()\n",
    "train_labels = train_data_filtered['gender_age_label'].values\n",
    "\n",
    "val_image_paths = val_data_filtered['img_path'].tolist()\n",
    "val_labels = val_data_filtered['gender_age_label'].values\n",
    "\n",
    "test_image_paths = test_data_filtered['img_path'].tolist()\n",
    "test_labels = test_data_filtered['gender_age_label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4c562693322fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Print dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d723cb6011dc27",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(f\"Training samples: {len(train_image_paths)}\")\n",
    "print(f\"Validation samples: {len(val_image_paths)}\")\n",
    "print(f\"Test samples: {len(test_image_paths)}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540445fddb53d20a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Extract features for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544690004cb7efa1",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(\"Extracting features for training data...\")\n",
    "print(f\"Processing all {len(train_image_paths)} training samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577176c90b39c29",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Define a function to extract features in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507def9ce8ee6db",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def extract_features_in_batches(image_paths, batch_size=64):\n",
    "    \"\"\"Extract features from images in batches to manage memory.\"\"\"\n",
    "    num_samples = len(image_paths)\n",
    "    num_batches = math.ceil(num_samples / batch_size)\n",
    "    all_features = []\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, num_samples)\n",
    "        \n",
    "        print(f\"\\rProcessing batch {i+1}/{num_batches}\", end=\"\")\n",
    "        \n",
    "        batch_paths = image_paths[start_idx:end_idx]\n",
    "        batch_features = gray2emb(batch_paths) / 255.0  # Normalize to [0,1]\n",
    "        \n",
    "        all_features.append(batch_features)\n",
    "    \n",
    "    print(\"\\nFeature extraction complete.\")\n",
    "    return np.vstack(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb956c7cd2c93c5",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "X_train = extract_features_in_batches(train_image_paths, batch_size=batch_size)\n",
    "y_train = train_labels\n",
    "\n",
    "print(\"Extracting features for validation data...\")\n",
    "print(f\"Processing all {len(val_image_paths)} validation samples\")\n",
    "\n",
    "X_val = extract_features_in_batches(val_image_paths, batch_size=batch_size)\n",
    "y_val = val_labels\n",
    "\n",
    "\n",
    "print(\"Creating and training AdaBoostClassifier model...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c08239aff4978",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create a pipeline with scaling and RandomeForest\n",
    "This is much more memory efficient for large datasets\n",
    "Create a pipeline that scales data (optional for RF) and then trains a RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0b5d10fadbd92",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scaling can be useful even though RF doesn't strictly require it\n",
    "    ('AB', AdaBoostClassifier(\n",
    "        n_estimators=100,          t\n",
    "                        \n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7caf0c672c1747",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### define the model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec53300e3cc175",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Fit the pipeline directly\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb26e7a3d7f5460",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195a63f484c1aee",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Extract features for test data\n",
    "print(\"Extracting features for test data...\")\n",
    "print(f\"Processing all {len(test_image_paths)} test samples\")\n",
    "\n",
    "X_test = extract_features_in_batches(test_image_paths, batch_size=batch_size)\n",
    "y_test = test_labels\n",
    "\n",
    "# Evaluate on test data\n",
    "test_preds = model.predict(X_test)  # Use X_test instead of test_data\n",
    "test_accuracy = accuracy_score(y_test, test_preds)  # Use y_test instead of test_data\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d0d57d8f2a719b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730004b56a5b749",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "\n",
    "# Set up figure size\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a heatmap without masking zero values for better visualization\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', linewidths=0.5, \n",
    "            xticklabels=gender_age_encoder.classes_,\n",
    "            yticklabels=gender_age_encoder.classes_)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "\n",
    "# Improve layout and save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300)  # Higher DPI for better quality\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d40b63f3111d1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3855f7a908e06",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Get the unique classes in your test data\n",
    "unique_classes = np.unique(y_test)\n",
    "\n",
    "# Generate classification report using the labels parameter\n",
    "report = classification_report(\n",
    "    y_test, \n",
    "    test_preds, \n",
    "    labels=unique_classes,\n",
    "    target_names=[gender_age_encoder.classes_[i] for i in unique_classes],\n",
    "    zero_division=0  # Handles the division by zero error by setting precision and recall to 0\n",
    ")\n",
    "\n",
    "# Print the classification report with better formatting\n",
    "print(\"=\" * 50)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\" * 50)\n",
    "print(report)\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77cc75766f79a15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87397dc9406a57df",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "dump(model, 'RF_gray_gender_age_classifier.joblib')\n",
    "dump(gender_age_encoder, 'gender_age_encoder.joblib')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb12004bfd9a5603",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Function to predict gender_age range for a new image\n",
    "def predict_gender_age(image_path, model, gender_age_encoder):\n",
    "    \"\"\"Predict gender and age for a given face image.\"\"\"\n",
    "    # Extract features\n",
    "    features = gray2emb([image_path]) / 255.0\n",
    "    \n",
    "    # Apply the same scaling used during training (if using a pipeline with StandardScaler)\n",
    "    if hasattr(model, 'named_steps') and 'scaler' in model.named_steps:\n",
    "        features = model.named_steps['scaler'].transform(features)\n",
    "    \n",
    "    # Make prediction\n",
    "    pred_class = model.predict(features)[0]\n",
    "    \n",
    "    # Get class probabilities if available\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        pred_probs = model.predict_proba(features)[0]\n",
    "        confidence = pred_probs[pred_class]\n",
    "    else:\n",
    "        # For AdaBoostClassifier without calibration, we can't get probabilities\n",
    "        # Use decision function instead as a rough proxy for confidence\n",
    "        decision_values = model.decision_function(features)\n",
    "        # Normalize to [0, 1] range roughly\n",
    "        confidence = 1 / (1 + np.exp(-np.abs(decision_values[0][pred_class])))\n",
    "    \n",
    "    # Convert to gender_age range\n",
    "    pred_gender_age_range = gender_age_encoder.classes_[pred_class]\n",
    "    \n",
    "    return pred_gender_age_range, confidence\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "# Load the model\n",
    "image_path = \"path/to/new/face/image.jpg\"\n",
    "model = load('linear_svc_gender_age_classifier.joblib')\n",
    "gender_age_encoder = load('gender_age_encoder.joblib')\n",
    "\n",
    "# Make prediction\n",
    "pred_gender_age, confidence = predict_gender_age(image_path, model, gender_age_encoder)\n",
    "print(f\"Predicted gender_age range: {pred_gender_age} with confidence {confidence:.2f}\")\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
